# SGS Curator App - Experiments

Experimental notebooks and prototypes for the SGS Curator App project, exploring chunking strategies, retrieval methods, and contradiction detection workflows.

## ğŸ¯ Purpose

This repository contains Jupyter notebooks used to:
- Evaluate different chunking strategies
- Test embedding models and retrieval approaches
- Prototype contradiction detection workflows
- Benchmark components before productionization
- Share experimental findings with the team

## ğŸ“ Repository Structure

```
sgs-curator-experiments/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ chunking/              # Chunking strategy experiments
â”‚   â”œâ”€â”€ retrieval/             # Retrieval and embedding experiments
â”‚   â”œâ”€â”€ contradiction_detection/  # Contradiction detection workflows
â”‚   â””â”€â”€ end_to_end/            # Full pipeline experiments
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_datasets/       # Test datasets (following Redmine structure)
â”œâ”€â”€ shared/                    # Shared utility code
â””â”€â”€ requirements.txt           # Common dependencies
```

## ğŸ““ Available Notebooks

### Chunking
- **chunking_exercise.ipynb** - Evaluates how different chunking strategies (fixed-size, recursive, semantic) affect the ability to detect contradictions using semantic similarity between chunks

### Retrieval
- Coming soon...

### Contradiction Detection
- Coming soon...

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- Jupyter Lab or Jupyter Notebook

### Installation

```bash
# Clone the repository
git clone https://github.com/open-pipeline-ai/sgs-curator-experiments.git
cd sgs-curator-experiments

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Launch Jupyter
jupyter lab
```

### Running Notebooks

Navigate to the `notebooks/` directory and open any `.ipynb` file.

Each notebook includes:
- Purpose and scope
- Workflow overview
- Step-by-step implementation
- Results and analysis

## ğŸ“Š Datasets

Test datasets follow the CuratorApp structure for evaluating chunking and contradiction detection.

Place datasets in `data/sample_datasets/` following the structure:
```
data/
â””â”€â”€ sample_datasets/
    â”œâ”€â”€ contradictory_docs/
    â”œâ”€â”€ consistent_docs/
    â””â”€â”€ mixed_scenarios/
```

**Note:** Large datasets should not be committed. Use `.gitignore` to exclude them.

## ğŸ¤ Contributing Experiments

We welcome experimental contributions! To add a new notebook:

1. **Choose the right category:**
   - `notebooks/chunking/` - Chunking strategies
   - `notebooks/retrieval/` - Retrieval and embeddings
   - `notebooks/contradiction_detection/` - Contradiction workflows
   - `notebooks/end_to_end/` - Full pipelines

2. **Follow the notebook template:**
   - Add a title and purpose section
   - Include workflow overview
   - Document parameters and configurations
   - Add results/findings section
   - Include references to related work

3. **Update requirements.txt** if you add new dependencies

4. **Create a PR** with your notebook and a brief description

## ğŸ”— Related Projects

- [chunking-toolkit](https://github.com/open-pipeline-ai/chunking-toolkit) - Production chunking library
- [retrieval-toolkit](https://github.com/open-pipeline-ai/retrieval-toolkit) - Production retrieval library
- SGS Curator App - Main application (link TBD)

## ğŸ“ Notebook Guidelines

When creating notebooks:

- âœ… Include clear purpose and scope at the top
- âœ… Document all dependencies and versions
- âœ… Use markdown cells to explain methodology
- âœ… Include results and analysis sections
- âœ… Reference datasets and external resources
- âœ… Keep notebooks focused on one experiment
- âœ… Add visualizations where helpful
- âŒ Don't commit large datasets or model files
- âŒ Don't include sensitive API keys (use environment variables)

## ğŸ› ï¸ Common Dependencies

Key libraries used across notebooks:

- **LangChain** - Text splitting and chunking
- **Sentence Transformers** - Embedding models
- **VLLM** - Local LLM inference
- **NumPy/Pandas** - Data manipulation
- **Matplotlib/Seaborn** - Visualization
- **scikit-learn** - Similarity metrics

See `requirements.txt` for complete list.

## ğŸ“„ License

This project is licensed under the GNU Lesser General Public License v3.0 or later (LGPLv3+) - see the [LICENSE](LICENSE) file for details.

## ğŸ¤” Questions?

- Open an issue in this repository
- Refer to the main [Curator App documentation](TBD)
- Contact the project maintainers

---

**Note:** This is an experimental repository. Production-ready code should be contributed to the respective toolkit repositories (chunking-toolkit, retrieval-toolkit).